{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "### Redes convolucionales\n",
    "\n",
    "\n",
    "En una capa de una red convolucional, una \"neurona\" hace una suma ponderada de los píxeles justo encima de ella, en una pequeña región de la imagen solamente. Luego actúa normalmente al agregar un sesgo y alimentar el resultado a través de su función de activación. La gran diferencia es que cada neurona reutiliza los mismos pesos, mientras que en las redes totalmente conectadas vistas anteriormente, cada neurona tiene su propio conjunto de pesos.\n",
    "\n",
    "\n",
    "Los dos (o más) conjuntos de pesos pueden reescribirse como uno al agregar una dimensión al tensor y esto nos da la forma genérica del tensor de pesos para una capa convolucional. Como la cantidad de canales de entrada y salida son parámetros, podemos comenzar a apilar y encadenar capas convolucionales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNISTdata\\train-images-idx3-ubyte.gz\n",
      "Extracting MNISTdata\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNISTdata\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNISTdata\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "NUM_ITERS=5000\n",
    "LOTES=100\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "mnist = read_data_sets(\"MNISTdata\", one_hot=True, reshape=False, validation_size=0)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkeep = tf.placeholder(tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capas\n",
    "\n",
    "C1 = 4  \n",
    "C2 = 8 \n",
    "C3 = 16 \n",
    "\n",
    "FC4 = 256 \n",
    "\n",
    "# Los pesos se inicializan con valores aleatorios desde una distribucion normal  estandar\n",
    "# la salidad de una capa es la entrada para la otra\n",
    "W1 = tf.Variable(tf.truncated_normal([5, 5, 1, C1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.truncated_normal([C1], stddev=0.1))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([3, 3, C1, C2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.truncated_normal([C2], stddev=0.1))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([3, 3, C2, C3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.truncated_normal([C3], stddev=0.1))\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([7*7*C3, FC4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.truncated_normal([FC4], stddev=0.1))\n",
    "\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([FC4, 10], stddev=0.1))\n",
    "b5 = tf.Variable(tf.truncated_normal([10], stddev=0.1))\n",
    "\n",
    "\n",
    "# Aplanamos las imágenes, se crea un  vector [784]\n",
    "#  -1 en la definición de shape significa que calculamos automáticamente el tamaño de esta dimensión\n",
    "\n",
    "XX = tf.reshape(X, [-1, 784])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo\n",
    "\n",
    "\n",
    "paso = 1  \n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, paso, paso, 1], padding='SAME') + b1)\n",
    "\n",
    "k = 2 \n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, paso, paso, 1], padding='SAME') + b2)\n",
    "Y2 = tf.nn.max_pool(Y2, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, paso, paso, 1], padding='SAME') + b3)\n",
    "Y3 = tf.nn.max_pool(Y3, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "YY = tf.reshape(Y3, shape=[-1, 7 * 7 * C3])\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(YY, W4) + b4)\n",
    "\n",
    "Ylogits = tf.matmul(Y4, W5) + b5\n",
    "Y = tf.nn.softmax(Ylogits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos una función de Tensorflow para softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropia_cruzada = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "entropia_cruzada= tf.reduce_mean(entropia_cruzada)*100\n",
    "\n",
    "                                                          \n",
    "# prediccion del modelo de entrenamiento\n",
    "prediccion_correcta = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "prediccion = tf.reduce_mean(tf.cast(prediccion_correcta, tf.float32))\n",
    "\n",
    "# Taza de aprendizaje\n",
    "paso_entrenamiento = tf.train.AdamOptimizer(0.003).minimize(entropia_cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancemos el modelo utilizando InteractiveSession:\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(NUM_ITERS+1):\n",
    "        # Entrenamiento de lotes  100 imagenes con 100 etiquetas\n",
    "        lote_X, lote_Y = mnist.train.next_batch(LOTES)\n",
    "        sess.run(paso_entrenamiento, feed_dict={X: lote_X, Y_:lote_Y, pkeep: 0.75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_correcta = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = tf.reduce_mean(tf.cast(prediccion_correcta, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calculamos precisión de nuestros datos de  prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9864\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(prediccion, feed_dict={X: mnist.test.images, Y_: mnist.test.labels, pkeep: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
