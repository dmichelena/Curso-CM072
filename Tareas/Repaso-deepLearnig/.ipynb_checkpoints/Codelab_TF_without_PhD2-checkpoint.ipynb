{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "### Redes neuronales profundas\n",
    "\n",
    "La función de activación sigmoidea en realidad es bastante problemática en redes profundas. Aplasta todos los valores entre 0 y 1 y cuando se utiliza repetidamente, las salidas de neuronas y sus gradientes pueden desaparecer por completo. Las redes modernas usan RELU (Rectified Linear Unit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNISTdata\\train-images-idx3-ubyte.gz\n",
      "Extracting MNISTdata\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNISTdata\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNISTdata\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "NUM_ITERS=5000\n",
    "LOTES=100\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "mnist = read_data_sets(\"MNISTdata\", one_hot=True, reshape=False, validation_size=0)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capas a mostrar\n",
    "L1 = 200\n",
    "L2 = 100\n",
    "L3 = 60\n",
    "L4 = 30\n",
    "L5 = 10\n",
    "\n",
    "# Los pesos se inicializan con valores aleatorios desde una distribucion normal  estandar\n",
    "# la salidad de una capa es la entrada para la otra\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([L1, L2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([L2, L3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([L3]))\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([L3, L4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([L4]))\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([L4, L5], stddev=0.1))\n",
    "b5 = tf.Variable(tf.zeros([L5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplanamos las imágenes, se crea un  vector [784]\n",
    "#  -1 en la definición de shape significa que calculamos automáticamente el tamaño de esta dimensión\n",
    "\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "# Definimos el modelo\n",
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + b1)\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + b2)\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + b3)\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3, W4) + b4)\n",
    "Ylogits = tf.matmul(Y4, W5) + b5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos una función de Tensorflow para softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropia_cruzada = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "entropia_cruzada= tf.reduce_mean(entropia_cruzada)*100\n",
    "\n",
    "                                                          \n",
    "# prediccion del modelo de entrenamiento\n",
    "prediccion_correcta = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "prediccion = tf.reduce_mean(tf.cast(prediccion_correcta, tf.float32))\n",
    "\n",
    "# Taza de aprendizaje\n",
    "paso_entrenamiento = tf.train.AdamOptimizer(0.003).minimize(entropia_cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancemos el modelo utilizando InteractiveSession:\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(NUM_ITERS+1):\n",
    "        # Entrenamiento de lotes  100 imagenes con 100 etiquetas\n",
    "        lote_X, lote_Y = mnist.train.next_batch(LOTES)\n",
    "        sess.run(paso_entrenamiento, feed_dict={X: lote_X, Y_:lote_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_correcta = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = tf.reduce_mean(tf.cast(prediccion_correcta, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, calculamos precisión de nuestros datos de  prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(prediccion, feed_dict={X: mnist.test.images, Y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
